{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPh+VUgNKpu63oRIUk+E5UU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basnugroho/thesis/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CDvy_ZXOhBj"
      },
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaLqJllfOzaV"
      },
      "source": [
        "Accessing google drive files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x5fY5VmOkau",
        "outputId": "343eaea2-471c-49df-cef8-5214ecf3a27d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swNwzU8MOtOo",
        "outputId": "4da56e64-b8e3-476d-e293-2062e3862165"
      },
      "source": [
        "data_df = pd.read_excel(\"/content/gdrive/MyDrive/S2 Informatika/thesis/data/dataset_tweet_isp_kecil.xlsx\")\n",
        "data_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 619 entries, 0 to 618\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      308 non-null    float64\n",
            " 1   tweet   619 non-null    object \n",
            " 2   isp     261 non-null    object \n",
            " 3   score   619 non-null    int64  \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 19.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6DBZCx47PqvU",
        "outputId": "a68876b0-1f67-48bd-b786-a9b261910c84"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>isp</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.374183e+18</td>\n",
              "      <td>@BiznetHome min cek DM ya, nanyak status konek...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.374166e+18</td>\n",
              "      <td>@BiznetHome udah min, hbs tweet trs bisa</td>\n",
              "      <td>biznet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.374153e+18</td>\n",
              "      <td>min tolong di cek koneksi internet saya @Bizne...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.374139e+18</td>\n",
              "      <td>@anggajalu Hi @anggajalu, DM mimin ID pelangga...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.374080e+18</td>\n",
              "      <td>@dwikaputra Hi @dwikaputra, DM mimin ID kamu y...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ... score\n",
              "0  1.374183e+18  ...     0\n",
              "1  1.374166e+18  ...     1\n",
              "2  1.374153e+18  ...     0\n",
              "3  1.374139e+18  ...     0\n",
              "4  1.374080e+18  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZnH8cSGQZps"
      },
      "source": [
        "Preprocessing (formating)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPnd53T1QNGB"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6auMfSOQd6_",
        "outputId": "ad683192-5549-45bf-e256-3c7c159a475b"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eAdgcAcQs_H"
      },
      "source": [
        "def clean_text(kata):\n",
        "    kata = str(kata)\n",
        "    kata = kata.lower()\n",
        "    \n",
        "    # remove hashtag\n",
        "    # kata = kata.replace('#', '')\n",
        "    \n",
        "    # remove punctuation\n",
        "    # kata = kata.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "    \n",
        "    #remove extra spaces\n",
        "    kata = kata.strip()\n",
        "\n",
        "    # remove space in encoding\n",
        "    # kata = kata.replace('< ', '<')\n",
        "    # kata = kata.replace(' >', '>')\n",
        "    # kata = kata.replace('@ ', '@')\n",
        "    \n",
        "    # remove non ascii chars\n",
        "    new_words = []\n",
        "    for word in kata:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    kata = \"\".join(new_words)\n",
        "\n",
        "    #upper encoded word\n",
        "    unlower_list = ['<url>', '<product_name>', '<provider_name>', '<user_mention>']\n",
        "    for word in kata.split():\n",
        "      if word in unlower_list:\n",
        "        kata = re.sub(word, word.upper(), kata)\n",
        "    return kata\n",
        "\n",
        "#replace string\n",
        "def find_replace(kata, kalimat):\n",
        "    list_to_replace = kalimat.split()\n",
        "    for i,word in enumerate(list_to_replace):\n",
        "        if kata in word:\n",
        "            list_to_replace[i] = kata\n",
        "    return \" \".join(list_to_replace)\n",
        "\n",
        "def remove_stopwords_id(kalimat):    \n",
        "    # ambil stopword bawaan\n",
        "    # stop_factory = StopWordRemoverFactory().get_stop_words()\n",
        "    \n",
        "    more_stopword = ['nih', 'sih', 'kok', 'hi', 'yah',\n",
        "                'mohon', 'nya', 'yg', 'wkwk', 'wkwkwk', 'wkwkwkwk']\n",
        "\n",
        "    # menggabungkan stopword\n",
        "    #data = stop_factory + more_stopword\n",
        "    data = stopwords_id + more_stopword\n",
        "\n",
        "    dictionary = ArrayDictionary(data)\n",
        "    string = StopWordRemover(dictionary)\n",
        "    tokens = nltk.tokenize.word_tokenize(string.remove(kalimat))\n",
        "    return(\" \".join(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WagL5hHiSpb7"
      },
      "source": [
        "def encode(kata):\n",
        "    kata = str(kata)\n",
        "    # encode urls\n",
        "    kata = re.sub(\"http*\\S+\", \"<URL>\", kata)\n",
        "\n",
        "    # contain product internet product name like; indihome, biznet, telkomsel\n",
        "    kata = re.sub(\"@bizne*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    kata = re.sub(\"@indihom*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    kata = re.sub(\"@di_cbn*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "\n",
        "    # contain hastagh product internet product name like; indihome, biznet, telkomsel\n",
        "    kata = re.sub(\"#biznet*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    kata = re.sub(\"#indihome*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    kata = re.sub(\"#di_cbn*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "\n",
        "    kata = re.sub(\"indi*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    kata = re.sub(\"indeh*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    kata = re.sub(\"indieho*\\S+\", \"<PRODUCT_NAME>\", kata)\n",
        "    \n",
        "    # contain ISP name like telkom\n",
        "    kata = re.sub(\"@telkom*\\S+\", \"<PROVIDER_NAME>\", kata)\n",
        "    kata = re.sub(\"#telkom*\\S+\", \"<PROVIDER_NAME>\", kata)\n",
        "\n",
        "    # remove full mentions\n",
        "    kata = re.sub(\"@\\S+\", \"<USER_MENTION>\", kata)\n",
        "\n",
        "    #\n",
        "    #kata = re.sub(\"#*\\S+\", \"<HASHTAG>\", kata)\n",
        "    \n",
        "    # emoji\n",
        "    # kata = re.sub(\"[\\u0001f600-\\u0001f64f]\", \"<EMOJI>\", kata)\n",
        "\n",
        "    # non ascii\n",
        "    re.sub(r'[^\\x00-\\x7F]+',' ', kata)\n",
        "    \n",
        "    return kata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uwcOmetlVcVa",
        "outputId": "c1b5a69a-2a55-498d-8d51-733ae476285d"
      },
      "source": [
        "# build cleaned and encoded dataset\n",
        "tweets_cleaned = [ clean_text(encode(tweet)) for tweet in data_df['tweet'] ]\n",
        "\n",
        "cleaned_df = pd.DataFrame(columns=['tweet', 'isp', 'score'])\n",
        "cleaned_df['tweet'] = tweets_cleaned\n",
        "cleaned_df['isp'] = data_df['isp']\n",
        "cleaned_df['score'] = data_df['score']\n",
        "cleaned_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>isp</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;USER_MENTION&gt; min cek dm ya, nanyak status ko...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;USER_MENTION&gt; udah min, hbs tweet trs bisa</td>\n",
              "      <td>biznet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>min tolong di cek koneksi internet saya &lt;USER_...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;USER_MENTION&gt; hi &lt;USER_MENTION&gt; dm mimin id p...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;USER_MENTION&gt; hi &lt;USER_MENTION&gt; dm mimin id k...</td>\n",
              "      <td>biznet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet     isp  score\n",
              "0  <USER_MENTION> min cek dm ya, nanyak status ko...  biznet      0\n",
              "1        <USER_MENTION> udah min, hbs tweet trs bisa  biznet      1\n",
              "2  min tolong di cek koneksi internet saya <USER_...  biznet      0\n",
              "3  <USER_MENTION> hi <USER_MENTION> dm mimin id p...  biznet      0\n",
              "4  <USER_MENTION> hi <USER_MENTION> dm mimin id k...  biznet      0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cau4qVd8hVuL",
        "outputId": "776b2f01-74a8-4816-e58b-aff46b4d8a63"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt update\n",
        "!apt install gcsfuse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "OK\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,385 B]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,335 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [581 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:19 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [454 B]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [613 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,770 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.0 kB]\n",
            "Fetched 13.1 MB in 4s (3,284 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "79 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 79 not upgraded.\n",
            "Need to get 10.8 MB of archives.\n",
            "After this operation, 23.2 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 0.36.0 [10.8 MB]\n",
            "Fetched 10.8 MB in 0s (85.4 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 155013 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.36.0_amd64.deb ...\n",
            "Unpacking gcsfuse (0.36.0) ...\n",
            "Setting up gcsfuse (0.36.0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0r-vzyewLAA"
      },
      "source": [
        "!pip freeze > '/content/gdrive/MyDrive/S2 Informatika/thesis/requirements.txt'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}